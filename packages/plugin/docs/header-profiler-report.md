# Header Profiler: Implementation Report

## Problem

When unbrowse replays API calls from Node.js (no browser), requests get blocked. The replay only sent `Content-Type: application/json` + auth headers. Real browser requests include `User-Agent`, `Accept`, `Referer`, `Origin`, `X-Requested-With`, and site-specific custom headers that anti-bot systems check.

Two user scenarios needed solving:
1. **Skill creator**: Captures a site, generates a skill — headers should be preserved in the skill
2. **Index user**: Downloads a skill from marketplace, has no original headers — needs to prime from their own browser

## Solution

A header template system: capture a frequency-based header profile during skill generation, hydrate it with fresh values from the user's browser at replay time.

### New File: `packages/plugin/src/header-profiler.ts`

Four exported functions:

| Function | Purpose |
|----------|---------|
| `classifyHeader(name)` | Categorizes headers: `protocol`, `browser`, `cookie`, `auth`, `context`, `app` |
| `buildHeaderProfiles(entries, domains)` | Builds frequency-based header templates from HAR traffic |
| `resolveHeaders(profile, domain, method, path, auth, cookies, mode)` | Merges template + overrides + auth + cookies into a final header set |
| `primeHeaders(targetUrl, profile, port)` | Opens browser via Playwright CDP, captures fresh headers + cookies |

### Header Categories

| Category | Examples | Replayed? |
|----------|----------|-----------|
| `protocol` | `:method`, `host`, `connection`, `content-length` | No — transport layer |
| `browser` | `sec-fetch-*`, `sec-ch-ua*`, `accept-encoding` | No — can't spoof from Node.js |
| `cookie` | `cookie`, `set-cookie` | Separate flow (cookie jar) |
| `auth` | `authorization`, `x-api-key`, `x-csrf-token` | From auth.json |
| `context` | `user-agent`, `accept`, `referer`, `origin` | Only in browser mode |
| `app` | Everything else (`x-requested-with`, `x-shopee-language`, etc.) | Always |

### Key Design Decision: `app` as Catch-All

Every website has unique custom headers. Shopee sends `x-shopee-language`. Reddit sends custom `priority` headers. Instead of maintaining a hardcoded list, any header not in the known categories becomes `app` and gets captured automatically via frequency analysis (>= 80% of requests to a domain).

## Eval Results

Tested against 10 real websites with 6 header strategies. Playwright captures HAR traffic, parseHar builds profiles, then endpoints are replayed from Node.js fetch with different header sets.

### Sites Tested

Reddit, Carousell, Hacker News, Wikipedia, NPM Registry, Stack Overflow, Amazon, eBay, YouTube, Shopee SG

### Strategy Comparison (5 key sites, 25 endpoints)

| Site | Bare | Node | N+Cookies | N+UA | Full | Exact |
|------|------|------|-----------|------|------|-------|
| Reddit | 1/5 | 1/5 | 1/5 | 1/5 | 1/5 | 2/5 |
| eBay | 1/5 | 1/5 | **2/5** | 2/5 | 2/5 | 2/5 |
| Shopee SG | 4/5 | 4/5 | 4/5 | 4/5 | 4/5 | 5/5 |
| Carousell | 5/5 | 5/5 | 5/5 | 5/5 | **4/5** | **4/5** |
| Stack Overflow | 4/5 | 4/5 | 4/5 | 4/5 | 4/5 | 4/5 |
| **Total** | 15/25 | 15/25 | **16/25** | 16/25 | **15/25** | 17/25 |

### Strategy Definitions

- **Bare**: No headers at all
- **Node**: App-only headers from profile (default mode)
- **N+Cookies**: App headers + session cookies from browser priming
- **N+UA**: App headers + generic `unbrowse/1.0` user-agent
- **Full**: All headers including Chrome User-Agent from Node.js
- **Exact**: Original captured headers replayed verbatim (includes cookies + context)

### Key Findings

1. **Full/browser mode is the worst strategy for Node.js.** Sending Chrome's User-Agent from Node.js triggers TLS fingerprint mismatch detection on Cloudflare/Akamai. Carousell: 5/5 bare → 4/5 full. Node.js TLS != Chrome TLS, and bot detectors check this.

2. **Node mode (app-only) is the safe default.** Never hurts, actively helps on sites with custom headers. It's now the default for `resolveHeaders()`.

3. **Cookie priming helps on some sites.** eBay: node=1/5 → node+cookies=2/5. Cookies never hurt — they match or beat node everywhere.

4. **The remaining gap (16 vs 17) is context headers** that can't be safely sent from Node.js without triggering TLS mismatch.

## Anti-Bot Deep Dive: Shopee `search_items`

The Shopee search API uses per-request anti-bot tokens generated by client-side JavaScript:

```
x-sap-sec:              Encrypted anti-bot signature (changes every request)
af-ac-enc-dat:          Anti-fraud encrypted data
af-ac-enc-sz-token:     Anti-fraud security token
sz-token:               Security token
d-nonptcha-sync:        Captcha sync token
x-csrftoken:            CSRF token (from cookie, must match)
x-sap-ri:               Per-request ID
```

**Even exact replay of captured headers returns error 90309999** — these tokens are one-time-use. The site's JS runtime generates them fresh on every request. No amount of header profiling can replicate this from Node.js.

This is why `execInChrome` exists as the primary replay path when a browser is available.

## Replay Architecture

The replay tool (`unbrowse_replay.ts`) uses a tiered strategy:

```
Browser available?
  YES → execInChrome(endpoint)
         ├── Runs fetch() INSIDE the browser page context
         ├── Site's JS generates fresh anti-bot tokens
         ├── Real TLS fingerprint matches User-Agent
         ├── cookies + CSRF handled natively
         └── Works on everything (including Shopee search_items)

  NO  → execViaFetch(endpoint)  [Node.js fallback]
         ├── primeHeaders() → connect to Chrome via CDP
         │   ├── Captures fresh header values
         │   └── Captures session cookies (16 from Shopee)
         ├── resolveHeaders() in "node" mode
         │   ├── App headers from profile (x-requested-with, etc.)
         │   ├── Cookies from priming
         │   ├── Auth from auth.json
         │   └── Skips context headers (avoids TLS mismatch)
         └── Works on ~64% of endpoints (simple APIs, no anti-bot)
```

## Browser Priming: Verified E2E

Tested `primeHeaders()` against a live Chrome instance (CDP port 18792) targeting Shopee:

```
Headers: 4 (2 hydrated fresh from browser, 2 fell back to template)
  Accept: application/json                          (fallback)
  User-Agent: Mozilla/5.0 ... HeadlessChrome/145    (FRESH)
  Referer: https://shopee.sg/search?keyword=laptop  (FRESH)
  X-Requested-With: XMLHttpRequest                  (fallback)

Cookies: 16 captured
  csrftoken, SPC_SEC_SI, SPC_F, SPC_T_ID, SPC_T_IV,
  SPC_SI, SPC_R_T_ID, SPC_R_T_IV, REC_T_ID, _sapid, ...
```

The `captureFromBrowser` function uses Playwright to:
1. Connect to running Chrome via CDP (tries ports 18792, 9222, 9229)
2. Falls back to launching headless Chromium if no Chrome found
3. Navigates to target URL, intercepts requests for header capture
4. Calls `context.cookies()` for cookie capture
5. Closes the page, returns headers + cookies

## Files Modified

| File | Changes |
|------|---------|
| `src/header-profiler.ts` | Created. `classifyHeader`, `buildHeaderProfiles`, `resolveHeaders` (default: node mode), `primeHeaders` (returns `PrimeResult` with headers + cookies), `captureFromBrowser` (Playwright CDP) |
| `src/types.ts` | Added `HeaderProfileFile`, `DomainHeaderProfile`, `CapturedHeader`, `EndpointHeaderOverride`, `HeaderCategory` interfaces |
| `src/har-parser.ts` | Calls `buildHeaderProfiles()` after parsing HAR, returns `headerProfile` on `ApiData` |
| `src/skill-generator.ts` | Writes `headers.json` to skill dir. Generated client loads profile and filters to `category === "app"` only |
| `src/plugin/tools/unbrowse_replay.ts` | Loads `headers.json`, calls `primeHeaders()` on first replay, merges primed cookies into session, uses `resolveHeaders()` in `execViaFetch()` |
| `src/plugin/tools/shared.ts` | Exports `resolveHeaders`, `primeHeaders`, `PrimeResult`, `BrowserCapturer` |

## Test Coverage

- **38 unit tests** in `test/header-profiler.test.ts` covering classification, profile building, header resolution (both modes), and primeHeaders with injected capturers
- **84 total tests** pass across the full suite
- **E2E eval** (`test/evals/capture-replay-eval.ts`) — 10 sites, 6 strategies, automated best-strategy detection
- **Live E2E** (`test/evals/test-prime.ts`, `test-prime-replay.ts`) — verified against real Shopee via Playwright CDP

## What Header Profiling Solves vs. Doesn't

### Solves
- Sites that check for custom app headers (Shopee `x-shopee-language`, Reddit `priority`)
- Sites that require session cookies for API access (eBay ticketing APIs)
- Sites where bare Node.js fetch gets 403'd but adding the right headers unblocks

### Doesn't Solve
- Per-request cryptographic anti-bot tokens (Shopee `x-sap-sec`, Cloudflare challenges)
- TLS fingerprint detection (sending Chrome UA from Node.js still looks like Node.js at the TLS level)
- Endpoints requiring active browser JS execution for token generation

For the "doesn't solve" cases, `execInChrome` is the correct path — it runs the fetch inside the browser where all protections are satisfied natively.

---

## Server Proxy Integration Contract (unbrowse-index)

This section specifies how the backend server (`unbrowse-index`) should consume the header profile when proxying API calls for cloud-mode skills.

### Overview

When a skill is published to the marketplace, the publish payload should include a sanitized `headerProfile` (the `HeaderProfileFile` JSON). The server stores this alongside the skill. At execution time, the server uses `resolveHeaders()` in **"node" mode** to build the outbound header set, replacing the current hardcoded `DEFAULT_BROWSER_HEADERS`.

### HeaderProfileFile JSON Schema (v1)

```json
{
  "version": 1,
  "domains": {
    "api.example.com": {
      "domain": "api.example.com",
      "commonHeaders": {
        "x-requested-with": {
          "name": "X-Requested-With",
          "value": "XMLHttpRequest",
          "category": "app",
          "seenCount": 12
        },
        "accept": {
          "name": "Accept",
          "value": "application/json",
          "category": "context",
          "seenCount": 15
        },
        "x-app-version": {
          "name": "X-App-Version",
          "value": "2.1.0",
          "category": "app",
          "seenCount": 14
        }
      },
      "requestCount": 15,
      "capturedAt": "2026-02-09T12:00:00.000Z"
    }
  },
  "endpointOverrides": {
    "POST /api/upload": {
      "endpointPattern": "POST /api/upload",
      "headers": {
        "content-type": "multipart/form-data"
      }
    }
  }
}
```

### TypeScript Types (canonical source: `packages/plugin/src/types.ts`)

```typescript
type HeaderCategory = "auth" | "browser" | "context" | "app" | "protocol" | "cookie";

interface CapturedHeader {
  name: string;           // Original case-preserving name
  value: string;          // Sample value (fallback for replay)
  category: HeaderCategory;
  seenCount: number;      // How many requests included this header
}

interface DomainHeaderProfile {
  domain: string;
  commonHeaders: Record<string, CapturedHeader>;  // Keyed by lowercased name
  requestCount: number;
  capturedAt: string;     // ISO timestamp
}

interface EndpointHeaderOverride {
  endpointPattern: string;  // e.g. "POST /api/upload"
  headers: Record<string, string>;
}

interface HeaderProfileFile {
  version: 1;
  domains: Record<string, DomainHeaderProfile>;
  endpointOverrides: Record<string, EndpointHeaderOverride>;
}
```

### Server-Side Usage: `resolveHeaders()` in "node" Mode

The server has no browser — it must use "node" mode exclusively. This means:

1. **Only `app` category headers are included** (e.g., `x-requested-with`, `x-app-version`, `x-shopee-language`).
2. **`context` headers are skipped** (`user-agent`, `accept`, `referer`, `origin`, etc.) — sending Chrome-like context headers from Node.js triggers TLS fingerprint mismatch detection on sites using Cloudflare/Akamai.
3. **`auth` headers come from the credential service**, not the profile.
4. **`cookie` headers come from the credential service** or session management, not the profile.
5. **`browser` and `protocol` headers are never included** — they are transport-layer or auto-generated.

#### Pseudocode: Server Integration

```typescript
// In ability-execution-service.ts, replace DEFAULT_BROWSER_HEADERS usage:

// 1. Load the header profile from the skill's stored data (DB or filesystem)
const headerProfile: HeaderProfileFile | undefined = skill.headerProfile;

// 2. Determine the target domain from the request URL
const domain = new URL(targetUrl).hostname;

// 3. Parse method and path from the request
const method = requestMethod;  // "GET", "POST", etc.
const path = new URL(targetUrl).pathname;

// 4. Resolve headers using "node" mode
//    - authHeaders: from credential service (decrypted for this execution)
//    - cookies: from credential service or session state
const resolvedHeaders = resolveHeaders(
  headerProfile,  // may be undefined for skills without a profile
  domain,
  method,
  path,
  authHeaders,    // Record<string, string> — from credential injection
  cookies,        // Record<string, string> — from session/credential service
  "node"          // ALWAYS "node" on the server — no browser available
);

// 5. Use resolvedHeaders as the base, merge with any runtime overrides
const finalHeaders = {
  ...resolvedHeaders,
  ...runtimeOverrides,  // e.g., Content-Type for POST requests
};
```

#### What Changes in `ability-execution-service.ts`

Current behavior (hardcoded):
```typescript
let mergedHeaders: Record<string, string> = { ...DEFAULT_BROWSER_HEADERS };
```

Proposed behavior (profile-driven):
```typescript
// Start with profile-resolved headers (app headers only in node mode)
let mergedHeaders: Record<string, string> = resolveHeaders(
  skill.headerProfile,
  targetDomain,
  method,
  path,
  {}, // auth injected separately in step 3
  {}, // cookies injected separately
  "node"
);

// Then merge code headers, static headers, credentials as before
```

The key insight: `resolveHeaders()` with `mode="node"` returns only the site-specific app headers that the site actually checks for. This is better than the current `DEFAULT_BROWSER_HEADERS` approach, which sends Chrome sec-fetch-* and sec-ch-ua* headers that can trigger TLS mismatch detection.

### Sanitization Rules for Publish

When a skill's header profile is included in the publish payload, it must be sanitized:

1. **Strip `auth` category headers entirely** — these contain Bearer tokens, API keys, CSRF tokens. The credential service handles auth separately.
2. **Strip `cookie` category headers** — session cookies are user-specific. The credential service manages cookies.
3. **Keep `app` category headers** — these are site-specific custom headers that are not sensitive (e.g., `x-requested-with: XMLHttpRequest`).
4. **Keep `context` category headers** — the server won't use them in "node" mode, but they provide documentation value and could be useful if the server gains browser support.
5. **Review header values** — ensure no values contain tokens, session IDs, or user-specific data. App headers like `x-app-version: 2.1.0` are safe; a header like `x-user-id: 12345` should be stripped.

The `buildHeaderProfiles()` function already excludes `auth`, `browser`, `protocol`, and `cookie` categories during profile construction, so the stored profile should be safe. However, as defense-in-depth, the server should also filter on its end.

### Database Schema Addition

The server needs a column to store the header profile:

```sql
ALTER TABLE skills ADD COLUMN header_profile JSONB DEFAULT NULL;
```

Or if using Drizzle schema:

```typescript
import { jsonb } from 'drizzle-orm/pg-core';

// In skills table definition:
headerProfile: jsonb('header_profile').$type<HeaderProfileFile>(),
```

### Publish Payload Extension

The `PublishPayload` interface needs a new optional field:

```typescript
interface PublishPayload {
  // ... existing fields ...
  /** Sanitized header profile for server-side proxy replay. */
  headerProfile?: HeaderProfileFile;
}
```

The plugin publish tool sends this; the server stores it. At execution time, the server loads it and passes it to `resolveHeaders()`.

### Versioning

The `HeaderProfileFile` has a `version: 1` field for forward compatibility. If the schema changes:
- Bump the version number.
- The server should check the version and handle accordingly (or reject unsupported versions).
- Older profiles (v1) continue to work with the v1 resolution logic.

### Fallback Behavior

If a skill has no header profile (published before header profiling existed, or profile was empty):
- `resolveHeaders(undefined, ...)` returns only auth + cookie headers (no app headers).
- The server falls back to its current behavior (using `DEFAULT_BROWSER_HEADERS` or no extra headers).
- No breakage — the profile is purely additive.

### Testing the Integration

From the plugin side, verify the contract with:

```typescript
import { resolveHeaders } from "./header-profiler.js";

// Simulate server-side usage
const profile: HeaderProfileFile = JSON.parse(readFileSync("headers.json", "utf-8"));
const headers = resolveHeaders(profile, "api.example.com", "GET", "/api/data", {}, {}, "node");

// Should contain ONLY app headers (no context, no browser, no auth, no cookies)
for (const [name, value] of Object.entries(headers)) {
  const category = classifyHeader(name);
  assert(category === "app", `Unexpected ${category} header in node mode: ${name}`);
}
```

The server side should have equivalent tests once `resolveHeaders()` is ported or imported.
